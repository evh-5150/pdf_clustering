# PDF 自動分類・整理ツール (PDF Auto-Clustering Tool)

## 1. 概要

このツールは，指定されたフォルダ内にある多数の PDF ファイルを，内容に基づいて自動的にクラスタリング (グループ分け) し，整理するための Python スクリプトです．
文書の内容を解析し，似たようなトピックを持つ PDF ファイルを同じグループにまとめます．さらに，各グループの内容を代表するキーワードを自動で抽出し，そのキーワードをフォルダ名として使用してファイルを整理します．

## 2. 主な機能

- **テキスト抽出**: PDF ファイルからテキスト情報を抽出します．
- **日本語形態素解析**: Janome ライブラリを使用し，日本語の文章を単語 (名詞，動詞など) に分割します．
- **ベクトル化 (TF-IDF)**: 各文書の特徴を捉えるために，単語の重要度を数値ベクトルに変換します．
- **次元削減 (LSA)**: 大量の特徴から本質的なトピックを抽出するために，次元削減を行います．
- **クラスタリング (HDBSCAN)**: 内容が似ている文書を自動でグループ分けします．どのグループにも属さない文書は「ノイズ」として扱われます．
- **キーワード抽出とフォルダ生成**: 各グループのテーマを表すキーワードを抽出し，`「cluster_ID_キーワード1_キーワード2」`のようなフォルダを自動で作成します．
- **ファイル整理**: 元の PDF ファイルを，分類されたキーワード付きのフォルダにコピーします．
- **結果のCSV出力**: どのファイルがどのクラスタに属するかをまとめた CSV ファイル (`clustering_results.csv`) を出力します．

## 3. 必要な環境

- Python 3.8 以上
- 以下の Python ライブラリが必要です．
pip install PyMuPDF pandas numpy janome scikit-learn hdbscan

## 4. 使い方

### ステップ 1: 準備

1.  このスクリプト (例: `main.py`) を任意の場所に保存します．
2.  スクリプトと同じ階層に `input` という名前のフォルダを作成します．
3.  整理したい PDF ファイルをすべて `input` フォルダにコピーします．

```
.
├── main.py         # このスクリプト
└── input/            # このフォルダを作成
    ├── report_A.pdf
    ├── document_B.pdf
    ├── manual_C.pdf
    └── ...
```

### ステップ2: 実行

ターミナル (またはコマンドプロンプト) を開き，スクリプトを実行します．

```bash
python main.py
```

処理が始まると，進行状況がログとして表示されます．処理時間は PDF の数や内容によって変動します．

### ステップ3: 結果の確認

処理が完了すると，`output` フォルダが自動で作成され，その中に結果が格納されます．

```
.
├── main.py
├── input/
│   ├── ... (元のPDFファイル)
└── output/           # このフォルダが生成される
    ├── clustering_results.csv  # 分類結果の全リスト
    ├── cluster_0_keywordA_keywordB/  # グループ 0 のフォルダ
    │   ├── report_A.pdf
    │   └── ...
    ├── cluster_1_keywordC_keywordD/  # グループ 1 のフォルダ
    │   ├── document_B.pdf
    │   └── ...
    └── cluster_noise/              # どのグループにも属さなかったファイル
        ├── manual_C.pdf
        └── ...
```

## 5. 出力について

- **キーワード付きフォルダ**: `output` フォルダ内に作成されます．`cluster_ID_キーワード...` という命名規則になっており，各グループの PDF ファイルが格納されています．
  - `cluster_noise` フォルダには，どのグループにも明確に分類されなかったファイル (ノイズ) が格納されます．
- **`clustering_results.csv`**: すべての PDF ファイルについて，どのクラスタ ID・フォルダに分類されたかを示す CSV ファイルです．

| filename | filepath | cluster_id | cluster_folder |
| :--- | :--- | :--- | :--- |
| report_A.pdf | ./input/report_A.pdf | 0 | cluster_0_keywordA_keywordB |
| document_B.pdf| ./input/document_B.pdf | 1 | cluster_1_keywordC_keywordD |
| manual_C.pdf | ./input/manual_C.pdf | -1 | cluster_noise |

## 6. 設定のカスタマイズ

スクリプト内の **「パラメータ調整エリア」** の値を変更することで，クラスタリングの挙動を調整できます．

```python
# --- パラメータ調整エリア ---
# MIN_DF = 2 が最も良い結果だったため，それを採用
MIN_DF = 2          # 文書に登場する回数がこの値未満の単語は無視
MAX_DF = 0.85       # 全文書の 85 % 以上に登場する一般的すぎる単語は無視
NGRAM_RANGE = (1, 2)  # 単語の組み合わせ (例:「機械学習」など 2 単語の組み合わせも考慮)
N_COMPONENTS = 50   # 文書から抽出するトピックの数 (次元数)．大きいほど詳細な特徴を捉えるが，計算量が増える．
MIN_CLUSTER_SIZE = 2 # クラスタを構成する最小のファイル数．この数に満たないグループはノイズになる．
MIN_SAMPLES = 1      # クラスタ内で「コア」と見なされる点の近傍数．小さいほどノイズが減る傾向．
METRIC = 'euclidean' # ベクトル間の距離計算方法．
# フォルダ名にするキーワードの数
NUM_KEYWORDS = 3
```

- **良い分類結果が得られない場合**:
  - `MIN_CLUSTER_SIZE` の値を小さくする (例: `2` -> `1`) と，より小さなグループが作られやすくなります．
  - `N_COMPONENTS` の値を調整してみてください．
  - `MIN_DF` を `1` にすると，より多くの単語が考慮されます．

## 7. 注意事項

- **テキスト抽出の限界**: このツールは，PDF 内にテキストデータが埋め込まれている場合にのみ機能します．スキャンされた画像がそのまま貼り付けられている PDF からは，テキストを抽出できません．
- **処理時間**: ファイル数や各 PDF のページ数が多い場合，処理に時間がかかることがあります．
- **既存のoutputフォルダ**: スクリプトを実行するたびに，既存の `output` フォルダは一度削除され，新しく作り直されます．必要なファイルは事前にバックアップしてください．
- **ファイル名の文字化け**: フォルダ名に使用できない文字 (`¥`, `/`, `:`, `*`, `?`, `"`, `<`, `>`, `|`) は，キーワード抽出時に自動的にアンダースコア (`_`) に置換されます．
