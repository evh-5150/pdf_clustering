# PDF自動分類・整理ツール (PDF Auto-Clustering Tool)

## 1. 概要

このツールは、指定されたフォルダ内にある多数のPDFファイルを、内容に基づいて自動的にクラスタリング（グループ分け）し、整理するためのPythonスクリプトです。

文書の内容を解析し、似たようなトピックを持つPDFファイルを同じグループにまとめます。さらに、各グループの内容を代表するキーワードを自動で抽出し、そのキーワードをフォルダ名として使用してファイルを整理します。

これにより、手作業では時間のかかる大量の文書整理を効率化し、未知の文書群の全体像を素早く把握することができます。

## 2. 主な機能

- **テキスト抽出**: PDFファイルからテキスト情報を抽出します。
- **日本語形態素解析**: Janomeライブラリを使用し、日本語の文章を単語（名詞、動詞など）に分割します。
- **ベクトル化 (TF-IDF)**: 各文書の特徴を捉えるために、単語の重要度を数値ベクトルに変換します。
- **次元削減 (LSA)**: 大量の特徴から本質的なトピックを抽出するために、次元削減を行います。
- **クラスタリング (HDBSCAN)**: 内容が似ている文書を自動でグループ分けします。どのグループにも属さない文書は「ノイズ」として扱われます。
- **キーワード抽出とフォルダ生成**: 各グループのテーマを表すキーワードを抽出し、`「cluster_ID_キーワード1_キーワード2」`のようなフォルダを自動で作成します。
- **ファイル整理**: 元のPDFファイルを、分類されたキーワード付きのフォルダにコピーします。
- **結果のCSV出力**: どのファイルがどのクラスタに属するかをまとめたCSVファイル (`clustering_results.csv`) を出力します。

## 3. 必要な環境

- Python 3.8以上
- 以下のPythonライブラリが必要です。

下記のコマンドで、必要なライブラリを一度にインストールできます。

```bash
pip install PyMuPDF pandas numpy janome scikit-learn hdbscan
```

## 4. 使い方

### ステップ1: 準備

1.  このスクリプト（例: `main.py`）を任意の場所に保存します。
2.  スクリプトと同じ階層に `input` という名前のフォルダを作成します。
3.  整理したいPDFファイルをすべて `input` フォルダにコピーします。

```
.
├── main.py         # このスクリプト
└── input/            # このフォルダを作成
    ├── report_A.pdf
    ├── document_B.pdf
    ├── manual_C.pdf
    └── ...
```

### ステップ2: 実行

ターミナル（またはコマンドプロンプト）を開き、スクリプトを実行します。

```bash
python main.py
```

処理が始まると、進行状況がログとして表示されます。処理時間はPDFの数や内容によって変動します。

### ステップ3: 結果の確認

処理が完了すると、`output` フォルダが自動で作成され、その中に結果が格納されます。

```
.
├── main.py
├── input/
│   ├── ... (元のPDFファイル)
└── output/           # このフォルダが生成される
    ├── clustering_results.csv  # 分類結果の全リスト
    ├── cluster_0_keywordA_keywordB/  # グループ0のフォルダ
    │   ├── report_A.pdf
    │   └── ...
    ├── cluster_1_keywordC_keywordD/  # グループ1のフォルダ
    │   ├── document_B.pdf
    │   └── ...
    └── cluster_noise/              # どのグループにも属さなかったファイル
        ├── manual_C.pdf
        └── ...
```

## 5. 出力について

- **キーワード付きフォルダ**: `output` フォルダ内に作成されます。`cluster_ID_キーワード...` という命名規則になっており、各グループのPDFファイルが格納されています。
  - `cluster_noise` フォルダには、どのグループにも明確に分類されなかったファイル（ノイズ）が格納されます。
- **`clustering_results.csv`**: すべてのPDFファイルについて、どのクラスタID・フォルダに分類されたかを示すCSVファイルです。Excelなどで開いて確認できます。

| filename | filepath | cluster_id | cluster_folder |
| :--- | :--- | :--- | :--- |
| report_A.pdf | ./input/report_A.pdf | 0 | cluster_0_keywordA_keywordB |
| document_B.pdf| ./input/document_B.pdf | 1 | cluster_1_keywordC_keywordD |
| manual_C.pdf | ./input/manual_C.pdf | -1 | cluster_noise |

## 6. 設定のカスタマイズ

スクリプト内の **「パラメータ調整エリア」** の値を変更することで、クラスタリングの挙動を調整できます。

```python
# --- パラメータ調整エリア ---
# MIN_DF = 2 が最も良い結果だったため、それを採用
MIN_DF = 2          # 文書に登場する回数がこの値未満の単語は無視
MAX_DF = 0.85       # 全文書の85%以上に登場する一般的すぎる単語は無視
NGRAM_RANGE = (1, 2)  # 単語の組み合わせ（例：「機械学習」など2単語の組み合わせも考慮）
N_COMPONENTS = 50   # 文書から抽出するトピックの数（次元数）。大きいほど詳細な特徴を捉えるが、計算量が増える。
MIN_CLUSTER_SIZE = 2 # クラスタを構成する最小のファイル数。この数に満たないグループはノイズになる。
MIN_SAMPLES = 1      # クラスタ内で「コア」と見なされる点の近傍数。小さいほどノイズが減る傾向。
METRIC = 'euclidean' # ベクトル間の距離計算方法。
# フォルダ名にするキーワードの数
NUM_KEYWORDS = 3
```

- **良い分類結果が得られない場合**:
  - `MIN_CLUSTER_SIZE` の値を小さくする（例: `2` -> `1`）と、より小さなグループが作られやすくなります。
  - `N_COMPONENTS` の値を調整してみてください。
  - `MIN_DF` を `1` にすると、より多くの単語が考慮されます。

## 7. 注意事項

- **テキスト抽出の限界**: このツールは、PDF内にテキストデータが埋め込まれている場合にのみ機能します。スキャンされた画像がそのまま貼り付けられているPDFからは、テキストを抽出できません（OCR機能は搭載していません）。
- **処理時間**: ファイル数や各PDFのページ数が多い場合、処理に時間がかかることがあります。
- **既存のoutputフォルダ**: スクリプトを実行するたびに、既存の `output` フォルダは一度削除され、新しく作り直されます。必要なファイルは事前にバックアップしてください。
- **ファイル名の文字化け**: フォルダ名に使用できない文字 (`¥`, `/`, `:`, `*`, `?`, `"`, `<`, `>`, `|`) は、キーワード抽出時に自動的にアンダースコア (`_`) に置換されます。
